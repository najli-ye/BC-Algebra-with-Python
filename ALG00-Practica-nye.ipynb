{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica Final\n",
    "\n",
    "Enhorabuena!!! Ya el haber llegado hasta aquí es un logro más en tu camino para ser un experto del Big Data y del Machine Learning!! \n",
    "\n",
    "\n",
    "<img src=\"./Images/happy.gif\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "Con esta práctica pondremos en valor todo lo que hemos visto a lo largo del módulo. Vamos allá!! 😄"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Multiconjuntos\n",
    "\n",
    "Este ejercicio pondrá a prueba tu habilidad resolver un problema usando vectores.\n",
    "\n",
    "**Objetivos**:\n",
    "- Usar `Python`\n",
    "- Asegurar los fundamentos matemáticos detrás de las operaciones con conjuntos.\n",
    "\n",
    "**Problema**: Implementar las operaciones de los multiconjuntos (utilizando las librerías y estructuras de datos vistas en el curso).\n",
    "\n",
    "**Datos:**\n",
    "\n",
    "Un multiconjunto es un conjunto en el que un elemento puede repetirse, es decir, cada elemento posee una multiplicidad (un número natural) que indica cuántas veces el elemento es miembro del conjunto. Por ejemplo, en el multiconjunto `{a, a, b, b, b, c}`, las multiplicidades de los miembros a, b, y c son 2, 3, y 1, respectivamente.\n",
    "\n",
    "Al igual que los conjuntos, poseen las siguientes características y operaciones:\n",
    "- Cardinalidad: indica el número de elementos del multiconjunto. Por ejemplo, la cardinalidad del multiconjunto `{a, a, b, b, b, c}` es 6 (la suma de sus multiplicidades).\n",
    "- Inserción: permite insertar una ocurrencia de un elemento en el multiconjunto.\n",
    "- Eliminación: permite eliminar una ocurrencia de un elemento del multiconjunto.\n",
    "- Comparación: compara dos multiconjuntos para determinar si son iguales.\n",
    "- Pertenencia: determina si un elemento pertenece al multiconjunto.\n",
    "- Subconjunto: determina si un multiconjunto es subconjunto de otro.\n",
    "- Unión: conjunción de todos los elementos de dos multiconjuntos (sumando sus multiplicidades si un elementos está en los dos).\n",
    "- Intersección: elementos que están en los dos multiconjuntos quedándonos con la multiplicidad más pequeña.\n",
    "- Diferencia: restar a un multiconjunto los elementos de otro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Crear una función que dada una lista devuelva un multiconjunto\n",
    "### El multiconjunto que devuelve puede crearse con la estructura de datos que se quiera (incluso una lista)\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "def multiconjunto(elementos):\n",
    "    \"\"\"\n",
    "    Devuelve un multiconjunto con la lista de elementos dada\n",
    "    \n",
    "    Argumentos:\n",
    "        elementos -- lista de elementos\n",
    "        \n",
    "    Ejemplo:\n",
    "        elementos = [1,1,1,3,3,1,4,5,1,5]\n",
    "    \"\"\"\n",
    "    return list(elementos.copy())\n",
    "    \n",
    "\n",
    "mc = multiconjunto([1,1,1,3,3,1,4,5,1,5])\n",
    "mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Crear una función que dado un multiconjunto devuelva su cardinalidad\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "def cardinalidad(multiconjunto):\n",
    "    \"\"\"\n",
    "    Devuelve la cardinalidad del multiconjunto dado\n",
    "    \n",
    "    Argumentos:\n",
    "        multiconjunto -- multiconjunto devuelto por la función creada anteriormente\n",
    "    \"\"\"\n",
    "    return len(multiconjunto)\n",
    "        \n",
    "\n",
    "cardinalidad(mc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Crear una función que dado un multiconjunto y un elemento devuelva el multiconjunto con el elemento insertado\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "def inserta(multiconjunto,elemento):\n",
    "    \"\"\"\n",
    "    Devuelve el multiconjunto habiendo insertado el elemento dado\n",
    "    \n",
    "    Argumentos:\n",
    "        multiconjunto -- multiconjunto devuelto por la función creada anteriormente\n",
    "        elemento -- elemento a insertar\n",
    "    \"\"\"   \n",
    "   # multic_mod = multiconjunto\n",
    "    return multiconjunto.copy() + [elemento]\n",
    "\n",
    "mc1 = inserta(mc,9)\n",
    "mc2 = inserta(mc,1)\n",
    "mc3 = inserta(mc,12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mc)\n",
    "print(mc1)\n",
    "print(mc2)\n",
    "print(mc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Crear una función que dado un multiconjunto y un elemento devuelva el multiconjunto con el elemento eliminado\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "def elimina(multiconjunto, elemento):\n",
    "    \"\"\"\n",
    "    Devuelve el multiconjunto habiendo eliminado una ocurrencia del elemento dado\n",
    "    \n",
    "    Argumentos:\n",
    "        multiconjunto -- multiconjunto devuelto por la función creada anteriormente\n",
    "        elemento -- elemento a eliminar\n",
    "    \"\"\"\n",
    "    #ir recorriendo la lista y coger los trozos sin el elemento dado por input\n",
    "    multic_mod = multiconjunto.copy()\n",
    "    for i in range(cardinalidad(multiconjunto)):\n",
    "        if multiconjunto[i] == elemento:\n",
    "            multic_mod = multiconjunto[:i] + multiconjunto [i+1:]\n",
    "    return multic_mod\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "mc = elimina(mc,9)\n",
    "mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc2_2 = elimina(mc2,1)\n",
    "mc2_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Crear una función que dado un multiconjunto y un elemento devuelva si el elemento pertenece al multiconjunto\n",
    "### TODO: Crear una función que dados dos multiconjuntos devuelva si el primero es subconjunto del segundo\n",
    "### TODO: Crear una función que dados dos multiconjuntos devuelva si son iguales\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "def pertenece(multiconjunto, elemento):\n",
    "    \"\"\"\n",
    "    Devuelve si el elemento pertenece al multiconjunto\n",
    "    \n",
    "    Argumentos:\n",
    "        multiconjunto -- multiconjunto devuelto por la función creada anteriormente\n",
    "        elemento -- elemento a determinar si pertenece\n",
    "    \"\"\"\n",
    "    return elemento in multiconjunto\n",
    "    \n",
    "\n",
    "def subconjunto(multiconjunto1, multiconjunto2):\n",
    "    \"\"\"\n",
    "    Devuelve si multiconjunto1 es subconjunto de multiconjunto2\n",
    "    \n",
    "    Argumentos:\n",
    "        multiconjunto1 -- multiconjunto devuelto por la función creada anteriormente\n",
    "        multiconjunto2 -- multiconjunto devuelto por la función creada anteriormente\n",
    "    \"\"\"\n",
    "    for i in multiconjunto1:\n",
    "        return pertenece(multiconjunto2, i)\n",
    "\n",
    "def iguales(multiconjunto1, multiconjunto2):\n",
    "    \"\"\"\n",
    "    Devuelve si multiconjunto1 es igual a multiconjunto2\n",
    "    \n",
    "    Argumentos:\n",
    "        multiconjunto1 -- multiconjunto devuelto por la función creada anteriormente\n",
    "        multiconjunto2 -- multiconjunto devuelto por la función creada anteriormente\n",
    "    \"\"\"\n",
    "    return multiconjunto1 == multiconjunto2\n",
    "\n",
    "print(pertenece(mc, 1))\n",
    "print(pertenece(mc, 5))\n",
    "print(pertenece(mc, 0))\n",
    "print('----')\n",
    "mc2 = multiconjunto([1,3,4])\n",
    "print(subconjunto(mc2, mc))\n",
    "print(subconjunto(multiconjunto([0,7,9,1]), mc))\n",
    "print('----')\n",
    "print(iguales(multiconjunto([1,3,4]), mc))\n",
    "print(iguales(mc, mc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Crear una función que dados dos multiconjuntos devuelva su unión\n",
    "### TODO: Crear una función que dados dos multiconjuntos devuelva su intersección\n",
    "### TODO: Crear una función que dados dos multiconjuntos devuelva su diferencia\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "def union(multiconjunto1, multiconjunto2):\n",
    "    \"\"\"\n",
    "    Devuelve la unión de los multiconjuntos sumando sus multiplicidades si un elementos está en los dos\n",
    "    \n",
    "    Argumentos:\n",
    "        multiconjunto1 -- multiconjunto devuelto por la función creada anteriormente\n",
    "        multiconjunto2 -- multiconjunto devuelto por la función creada anteriormente\n",
    "    \"\"\"\n",
    "    return multiconjunto(multiconjunto1.copy() + multiconjunto2.copy())\n",
    "\n",
    "\n",
    "def interseccion(multiconjunto1, multiconjunto2):\n",
    "    \"\"\"\n",
    "    Devuelve la intersección de los multiconjunto, quedándonos con la multiplicidad más pequeña\n",
    "    \n",
    "    Argumentos:\n",
    "        multiconjunto1 -- multiconjunto devuelto por la función creada anteriormente\n",
    "        multiconjunto2 -- multiconjunto devuelto por la función creada anteriormente\n",
    "    \"\"\"\n",
    "    # todos los elementos comunes a mc1 y a mc2\n",
    "    intersecc = []\n",
    "    for i in multiconjunto1: \n",
    "        if i in multiconjunto2 and i not in intersecc:\n",
    "            intersecc.append(i)\n",
    "    return intersecc\n",
    "\n",
    "def diferencia(multiconjunto1, multiconjunto2):\n",
    "    \"\"\"\n",
    "    Devuelve la diferencia de los multiconjuntos, restar a un multiconjunto los elementos de otro\n",
    "    Todo lo que está en mc1 y no está en mc2.\n",
    "    No puedes deber elementos.Si tienes menos que el otro pues le das todos y ya está\n",
    "    \n",
    "    Argumentos:\n",
    "        multiconjunto1 -- multiconjunto devuelto por la función creada anteriormente\n",
    "        multiconjunto2 -- multiconjunto devuelto por la función creada anteriormente\n",
    "    \"\"\"\n",
    "#     {1,1,2,2} - {1,2} = {1,2}\n",
    "    mc_diff = multiconjunto1\n",
    "    for i in multiconjunto2: \n",
    "            if i in multiconjunto1:\n",
    "                mc_diff = elimina(mc_diff, i)\n",
    " #               print (mc_diff)\n",
    "    return mc_diff\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "# print(union(multiconjunto([1,3,4]), mc))\n",
    "# print(union(multiconjunto([1, 1, 1, 2, 3]), multiconjunto([1, 1, 2, 5])))\n",
    "print(interseccion(multiconjunto([1,3,4]), mc))\n",
    "print(interseccion(mc2, mc))\n",
    "print(interseccion(multiconjunto([1,1,3,4,4]), multiconjunto([2,3,5,4])))\n",
    "# {1, 1, 1, 2, 3} UNION {1, 1, 2, 5}  = {1, 1, 1, 1, 1, 2, 2, 3, 5}\n",
    "# print(diferencia(mc, multiconjunto([1,2,3,4])))\n",
    "# print(diferencia(multiconjunto([1,1,2,2,3,3,4,4]), multiconjunto([1,2,3,4]))) #1,2,3,4\n",
    "# print(diferencia(multiconjunto([1,1,2,2,3,3,4,4]), multiconjunto([1,2]))) #1,2,3,3,4,4\n",
    "print(diferencia(multiconjunto([1, 1, 1, 1, 1, 2, 2, 3, 5]), multiconjunto([1, 1, 1, 2, 3, 4]))) \n",
    "#{1, 1, 2, 5}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Singular Value Decomposition\n",
    "\n",
    "Este ejercicio pondrá a prueba tu habilidad para usar Singular Value Decomposition para comprimir una imagen.\n",
    "\n",
    "**Objetivos**\n",
    "- Usar `Python`\n",
    "- Entender los fundamentos de `SVD`.\n",
    "\n",
    "**Problema:** Usar `SVD` para comprimir una imagen en blanco y negro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La imagen que deberas usar es la siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy import misc\n",
    "%matplotlib inline\n",
    "\n",
    "# Load image\n",
    "A = misc.face(gray=True)\n",
    "\n",
    "plt.imshow(A, cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deberas crear tu propia función para calcular el error de reconstrucción, que viene definido por:\n",
    "\n",
    "$$SSE =  \\sum_{n}^{i=1}  \\begin{Vmatrix}x_{i} -  \\widehat{x}_i \\end{Vmatrix} ^2 $$\n",
    "\n",
    "Donde:\n",
    "\n",
    "- $x_i$ son los valores de la matriz original X\n",
    "- $\\widehat{x}_i$ son los valores de la matriz reconstruida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Función para calcular el error de reconstrucción\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def sse_score(X, X_hat):\n",
    "    \"\"\"\n",
    "    Función para calcular el error de reconstrucción\n",
    "    \n",
    "    Argumentos:\n",
    "        X -- Matriz Original\n",
    "        X_hat -- Matriz Reconstruida\n",
    "        \n",
    "    Ejemplo:\n",
    "        X = np.array([[1, 2], [3, 4]])\n",
    "        X_hat = np.array([[1.01, 1.75], [2.81, 3.99]])\n",
    "        sse = sse_score(X, X_hat) # -> 0.09879\n",
    "    \"\"\"\n",
    "    SSE = np.sum((X - X_hat)**2)\n",
    "    return SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1, 2], [3, 4]])\n",
    "X_hat = np.array([[1.01, 1.75], [2.81, 3.99]])\n",
    "sse = sse_score(X, X_hat) # -> 0.09879\n",
    "sse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que ya tenemos la función `sse` hecha, podemos pasar a construir la función que ejecutará `SVM`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Función para ejecutar SVM\n",
    "### Tiene como entrada una matriz X\n",
    "### Devuelve U, s, Vt\n",
    "\n",
    "### Hint: S debe ser una matriz diagonal\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "def svm(X):\n",
    "    \"\"\"\n",
    "    Función que ejecuta SVM y devuelve U, S, Vt\n",
    "    \n",
    "    Argumentos:\n",
    "        X -- Matriz Original\n",
    "        \n",
    "    Ejemplo:\n",
    "        X = np.array([[1, 2], [3, 4]])\n",
    "        U, S, Vt = svm(X)  \n",
    "        \n",
    "        # -> U = array([[-0.40455358, -0.9145143 ],\n",
    "        #               [-0.9145143 ,  0.40455358]])\n",
    "        # -> S = array([[5.4649857 , 0.        ],\n",
    "        #               [0.        , 0.36596619]])   \n",
    "        # -> Vt = array([[-0.57604844, -0.81741556],\n",
    "        #                [ 0.81741556, -0.57604844]])          \n",
    "    \"\"\" \n",
    "    U, s, Vt = np.linalg.svd(X, full_matrices=False)\n",
    "    S = np.diag(s)\n",
    "    return U, S, Vt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1, 2], [3, 4]])\n",
    "U, S, Vt = svm(X)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U\n",
    "print(\"U : \\n\", np.round(U, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S\n",
    "print(\"s : \\n\", np.round(S, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vt\n",
    "print(\"Vt : \\n\", np.round(Vt, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como hemos visto en clase, las matrices obtenidas a partir de `SVM` nos sirven para reconstruir la matriz original `X`. Para ello, construye una función que permita reconstruir la matriz original `X` a partir de `U, s, Vt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Función para reconstruir la matriz original a partir de U, s, Vt\n",
    "### Tiene como entrada U, s, Vt\n",
    "### Devuelve X_hat\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "\n",
    "def reconstruction(U, S, Vt):\n",
    "    \"\"\"\n",
    "    Función que reconstruye la matriz original a partir de U, s, Vt\n",
    "    \n",
    "    Argumentos:\n",
    "        U -- Matriz de Singular Vectors\n",
    "        s -- Matriz de Eigenvalues\n",
    "        Vt -- Matriz de Singular Vectors\n",
    "        \n",
    "    Ejemplo:\n",
    "        U = np.array([[-0.40455358, -0.9145143 ],\n",
    "                      [-0.9145143 ,  0.40455358]])\n",
    "        S = np.array([[5.4649857 , 0.        ],\n",
    "                      [0.        , 0.36596619]])\n",
    "        Vt = np.array([[-0.57604844, -0.81741556],\n",
    "                       [ 0.81741556, -0.57604844]])\n",
    "        X_hat = reconstruction(U, S, Vt)\n",
    "        \n",
    "        # X_hat -> array([[0.99999999, 1.99999998],\n",
    "        #                 [3.00000003, 4.00000001]])\n",
    "    \"\"\"\n",
    "#     X_hat = U @ S @ Vt\n",
    "    X_hat = U.dot(S.dot(Vt))\n",
    "    return X_hat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U = np.array([[-0.40455358, -0.9145143 ],\n",
    "                [-0.9145143 ,  0.40455358]])\n",
    "S = np.array([[5.4649857 , 0.        ],\n",
    "                [0.        , 0.36596619]])\n",
    "Vt = np.array([[-0.57604844, -0.81741556],\n",
    "                [ 0.81741556, -0.57604844]])\n",
    "\n",
    "X_hat = reconstruction(U, S, Vt)\n",
    "X_hat\n",
    "#type(X_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcula el error de reconstrucción usando la función `sse` que has programado anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sse_score(X, X_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que hemos programado todas las funciones necesarias para realizar `SVM` y medir el error de reconstrucción, podemos proceder a realizar la compresión de la imagen. Esta [página web](http://timbaumann.info/svd-image-compression-demo/) te ayudará a repasar y a entender como calcular la compresión.\n",
    "\n",
    "Debes usar la siguiente imagen: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image\n",
    "A = misc.face(gray=True)\n",
    "\n",
    "plt.imshow(A, cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Función que recibe una imagen A y devuelve la imagen comprimida\n",
    "### Tiene como entrada A y el número de componentes para realizar la reducción de dimensionalidad\n",
    "### Devuelve la imagen comprimida, el error de reconstrucción y el ratio de compresión\n",
    "\n",
    "### Hint: Usa las funciones anteriormente construidas\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "\n",
    "def image_compression(A, n_components):\n",
    "    \"\"\"\n",
    "    Función para comprimir una imagen A\n",
    "    \n",
    "    Argumentos:\n",
    "        A -- Imagen original\n",
    "        n_components -- Número de componentes\n",
    "        \n",
    "    Ejemplo:\n",
    "        A_hat, sse, comp_ratio = image_compression(A, n_components=50)\n",
    "    \"\"\"\n",
    "    #calculamos svm de la imagen original\n",
    "    U_A, s_A, V_A = svm(A)\n",
    "    \n",
    "    #reducimos las matrices segun el n_componentes que queramos comprimir la imagen\n",
    "    U_red = U_A[:, :n_components] # m x r\n",
    "    s_red = s_A[:n_components, :n_components] # r x r\n",
    "    Vt_red = V_A[:n_components, :]  # r x n\n",
    "    \n",
    "    #imagen comprimida reconstruida a partir de las matrices reducidas\n",
    "    A_hat_rec = reconstruction(U_red, s_red, Vt_red)\n",
    "    \n",
    "    #calculamos error de reconstrucción y ratio de compresión\n",
    "    sse = sse_score(A, A_hat_rec)\n",
    "    comp_ratio = (A.shape[1]*n_components + n_components + A.shape[0] * n_components) / (A.shape[1] * A.shape[0])\n",
    "    \n",
    "    return A_hat_rec, sse, comp_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grafica la imagen original `X` y la imagen reconstruida `X_hat`, y imprime el error de reconstrucción `sse` y el `ratio de compresion`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_hat, sse_A, comp_ratio_A = image_compression(A, n_components=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = misc.face(gray=True)\n",
    "\n",
    "plt.imshow(A, cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "A_hat = misc.face(gray=True)\n",
    "\n",
    "plt.imshow(A_hat, cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sse_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_ratio_A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Linear Regression - Least Squares\n",
    "\n",
    "Este ejercicio pondrá a prueba tu habilidad para programar tu propia versión de mínimos cuadrados en Python.\n",
    "\n",
    "**Objetivos**:\n",
    "- Usar `Python` + `Pandas` para leer y analizar los datos.\n",
    "- Asegurar los fundamentos matemáticos detrás del método de los mínimos cuadrados.\n",
    "\n",
    "**Problema**: Usando datos sobre el precio de la vivienda, intentaremos predecir el precio de una casa en base a la superficie habitable con un modelo de regresión.\n",
    "\n",
    "**Datos:** [Kaggle's House Prices Dataset](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repaso\n",
    "\n",
    "Usaremos la versión matricial de la solución de los **métodos de los mínimos cuadrados** para resolver este problema. Como recordatorio, expresamos los coeficientes $w_{LS}$ como un vector, y calculamos ese vector en base a la matriz de entrada $X$ y en base a $y$.<br><br>\n",
    "\n",
    "\n",
    "\n",
    "Como mostramos en clase, la matriz $X$ siempre contiene un vector de valores $1$ en la primera columna. En otras palabras:<br><br>\n",
    "\n",
    "<center>$\n",
    "X = \\begin{bmatrix}\n",
    "1 \\  x_{11}  \\\\\n",
    "1 \\  x_{21}  \\\\\n",
    "\\vdots \\ \\vdots \\\\\n",
    "1 \\ x_{n1}\n",
    "\\end{bmatrix} \n",
    "$</center>\n",
    "\n",
    "Para dos variables, $X$ tomará esta forma:\n",
    " \n",
    "<center>$\n",
    "X = \\begin{bmatrix}\n",
    "1 \\  x_{11} \\  x_{12} \\\\\n",
    "1 \\  x_{21} \\  x_{22} \\\\\n",
    "\\vdots \\ \\vdots \\\\\n",
    "1 \\ x_{n1} \\  x_{n2}\n",
    "\\end{bmatrix} \n",
    "$</center>\n",
    "\n",
    "### Exploratorio de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (20.0, 10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Leer los datos\n",
    "tr_path = './data/train.csv'\n",
    "data = pd.read_csv(tr_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### La función .head() muestras las primeras lineas de los datos\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lista con los nombres de las columnas\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Numero de columnas \n",
    "### Asignar int variable a: ans1\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "ans1 = len(data.columns)\n",
    "ans1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Podemos graficar los datos price vs living area - Matplotlib\n",
    "\n",
    "Y = data['SalePrice']\n",
    "X = data['GrLivArea']\n",
    "\n",
    "plt.scatter(X, Y, marker = \"x\")\n",
    "\n",
    "### Anotaciones\n",
    "plt.title(\"Sales Price vs. Living Area (excl. basement)\")\n",
    "plt.xlabel(\"GrLivArea\")\n",
    "plt.ylabel(\"SalePrice\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### price vs year - Pandas\n",
    "\n",
    "data.plot('YearBuilt', 'SalePrice', kind = 'scatter', marker = 'x');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión Lineal\n",
    "\n",
    "Ya que conocemos la ecuación para $w_{LS}$ tenemos todo lo necesario para resolver la regresión lineal. Vamos allá!<br><br>\n",
    "\n",
    "<center>$w_{LS} = (X^T X)^{-1}X^T y,$</center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Función para invertir una matriz\n",
    "### Construye una función que toma como input una matriz\n",
    "### Devuelve la inversa de dicha matriz\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "def inverse_of_matrix(mat):\n",
    "    \"\"\"Calcula y devuelve la inversa de la matriz\n",
    "    \n",
    "    Argumentos:\n",
    "        mat -- Matriz cuadrada a invertir\n",
    "        \n",
    "    Ejemplo:\n",
    "        sample_matrix = [[1, 2], [3, 4]]\n",
    "        the_inverse = inverse_of_matrix(sample_matrix)  \n",
    "        # -> the_inverse = [[-2.   1. ]\n",
    "        #                   [ 1.5 -0.5]]\n",
    "    \n",
    "    Requerimientos:\n",
    "        Esta función depende de 'numpy.linalg.inv'\n",
    "    \"\"\"\n",
    "    return np.linalg.inv(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_matrix = [[1, 2], [3, 4]]\n",
    "the_inverse = inverse_of_matrix(sample_matrix)\n",
    "the_inverse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leer los datos\n",
    "\n",
    "Lo primero que debemos hacer es leer los datos, para ello construye una función que reciba el directorio de un archivo .csv `file_path` y lo lea usando `pandas`, la función debe devolver el dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Función para leer un .csv\n",
    "### La función recibe un file_path y debe devolver el dataframe\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def read_to_df(file_path):\n",
    "    \"\"\"Leer un archivo .csv\"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df\n",
    "    \n",
    "    \n",
    "dataframe = read_to_df(tr_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subset del dataframe por columnas\n",
    "\n",
    "Queremos construir una función que nos permita obtener los datos de ciertas columnas. Por ello, le pasaremos como argumento un `dataframe` y una lista con los nombres de las columnas que queremos extraer `column_names` y nos devolverá un dataframe con solo esas columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Función para extraer los datos de ciertas columnas\n",
    "### Como argumentos, recibe un dataframe `data_frame`y una lista con los nombres de las columnas `column_names`\n",
    "### Devuelve un dataframe con solo las columnas que le hemos especificado\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "def select_columns(data_frame, column_names):\n",
    "    \"\"\"Devuelve un subset del dataframe en base a los nombres de las columnas\n",
    "    \n",
    "    Argumentos:\n",
    "        data_frame -- Dataframe Object\n",
    "        column_names -- Lista con los nombres de las columnas a seleccionar\n",
    "        \n",
    "    Ejemplo:\n",
    "        data = read_into_data_frame('train.csv')\n",
    "        selected_columns = ['SalePrice', 'GrLivArea', 'YearBuilt']\n",
    "        sub_df = select_columns(data, selected_columns)\n",
    "    \"\"\"\n",
    "    df_mini = data_frame.filter(items=column_names)\n",
    "    return df_mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_to_df('./data/train.csv')\n",
    "selected_columns = ['SalePrice', 'GrLivArea', 'YearBuilt']\n",
    "sub_df = select_columns(data, selected_columns)\n",
    "sub_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subset del dataframe por valores\n",
    "\n",
    "El siguiente paso es construir una función que recibe un `data_frame`, el nombre de una columna, un valor mínimo y un valor máximo `cutoffs`. Nos devuelve un dataframe excluyendo las filas donde el valor de la columna indica está fuera de los valores mínimos y máximos que le hemos indicado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Función para crear un nuevo subset en base a valores\n",
    "### Como argumento recibe un dataframe y una lista de tuples\n",
    "### Tuples: (column_name, min_value, max_value)\n",
    "### Devuelve un dataframe que excluye las filas donde los valores, en la columna que le hemos indicado, exceden los valores\n",
    "### que le hemos indicado\n",
    "### No eliminar la fila si los valores son iguales al min/max valor\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "def column_cutoff(data_frame, cutoffs):\n",
    "    \"\"\"Crea un nuevo dataframe en base a unos límites\n",
    "    \n",
    "    Argumentos:\n",
    "        data_frame -- Dataframe Object\n",
    "        cutoffs -- Lista de tuples con el siguiente formato:\n",
    "        (column_name, min_value, max_value)\n",
    "        \n",
    "    Ejemplo:\n",
    "        data_frame = read_into_data_frame('train.csv')\n",
    "        # Remove data points with SalePrice < $50,000\n",
    "        # Remove data points with GrLiveAre > 4,000 square feet\n",
    "        cutoffs = [('SalePrice', 50000, 1e10), ('GrLivArea', 0, 4000)]\n",
    "        selected_data = column_cutoff(data_frame, cutoffs)\n",
    "    \"\"\"\n",
    "#     for item in cutoffs:\n",
    "#         df_filter = data_frame.filter(items=item[0])\n",
    "\n",
    "    #primero selecciono las columnas que quiero:\n",
    "    df_column = data_frame.filter(items=(item[0] for item in cutoffs))\n",
    "  \n",
    "    #ahora escoger las filas que quiero, con valores entre item[1] e item[2] de cutoffs\n",
    "    for item in cutoffs:\n",
    "        min_mask = df_column[item[0]] > item[1]\n",
    "        max_mask = df_column[item[0]] < item[2]\n",
    "            \n",
    "    df_filter = df_column[min_mask][max_mask]  \n",
    "\n",
    "    return df_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = read_to_df('./data/train.csv')\n",
    "# Remove data points with SalePrice < $50,000\n",
    "# Remove data points with GrLiveAre > 4,000 square feet\n",
    "cutoffs = [('SalePrice', 50000, 1e10), ('GrLivArea', 0, 4000)]\n",
    "selected_data = column_cutoff(data_frame, cutoffs)\n",
    "selected_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mínimos Cuadrados / Least Squares\n",
    "\n",
    "Ahora, implementarás la ecuación $w_{LS}$:\n",
    "\n",
    "<center>$w_{LS} = (X^T X)^{−1}X^T y,$</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Función para resolver la ecuación wLS\n",
    "### Toma como argumentos dos matrices, una para X y otra para y\n",
    "### Asumimos que las matrices tienen las dimensiones correctas\n",
    "\n",
    "### Paso 1: Asegurate que n > d. \n",
    "### Es decir, que el número de observaciones es mayor que el número de dimensiones.\n",
    "### O lo que es lo mismo, que el número de filas de cada matriz sea mayor que el número de columnas\n",
    "### Si no es así, debes transponer las matrices\n",
    "\n",
    "### Paso 2: Debes añadir a la matriz X un vector columna del tamaño (n x 1)\n",
    "\n",
    "### Paso 3: Usa la ecuación de arriba para obtener wLS\n",
    "\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "\n",
    "def least_squares_weights(input_x, target_y):\n",
    "    \"\"\"Resuelve la ecuación para wLS\n",
    "    \n",
    "    Argumentos:\n",
    "        input_x -- Matriz con los datos de entrenamiento\n",
    "        target_y -- Vector con los datos de salida\n",
    "        \n",
    "    Ejemplo:\n",
    "        import numpy as np\n",
    "        training_y = np.array([[208500, 181500, 223500, \n",
    "                                140000, 250000, 143000, \n",
    "                                307000, 200000, 129900, \n",
    "                                118000]])\n",
    "        training_x = np.array([[1710, 1262, 1786, \n",
    "                                1717, 2198, 1362, \n",
    "                                1694, 2090, 1774, \n",
    "                                1077], \n",
    "                               [2003, 1976, 2001, \n",
    "                                1915, 2000, 1993, \n",
    "                                2004, 1973, 1931, \n",
    "                                1939]])\n",
    "        weights = least_squares_weights(training_x, training_y)\n",
    "        \n",
    "        print(weights)  #--> np.array([[-2.29223802e+06],\n",
    "                        #              [ 5.92536529e+01],\n",
    "                        #              [ 1.20780450e+03]])\n",
    "                           \n",
    "        print(weights[1][0]) #--> 59.25365290008861\n",
    "    \n",
    "    Asumimos:\n",
    "        -- target_y es un vector con el mismo número de observaciones que input_x\n",
    "    \"\"\"\n",
    "    \n",
    "    #chequeamos que tenemos más filas que columnas (más observaciones que dimensiones) en ambas matrices:\n",
    "    filas = input_x.shape[0]\n",
    "    columnas = input_x.shape[1]\n",
    "    \n",
    "    if filas < columnas: #Asumimos que target_y es un vector con el mismo número de observaciones que input_x\n",
    "        input_x = np.transpose(input_x) #transponemos y sobreescribimos ambas matrices\n",
    "        target_y = np.transpose(target_y)    \n",
    "        \n",
    "    #añadimos la columna con todo [1] a matriz input_x, renombrándola como X:\n",
    "    v = np.ones((input_x.shape[0],1))\n",
    "    X = np.hstack([v, input_x])    \n",
    "    \n",
    "    #Ecuación 𝑤𝐿𝑆=(𝑋𝑇𝑋)−1𝑋𝑇𝑦, siendo X la matriz modificada con el vector de 1s\n",
    "    X_t = np.transpose(X)\n",
    "    X_p = X_t @ X\n",
    "    X_inv = inverse_of_matrix(X_p)\n",
    "    \n",
    "    #ecuacion matricial minimos cuadrados\n",
    "    weights = X_inv @ (X_t @ target_y)\n",
    "       \n",
    "    return weights\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "training_y = np.array([[208500, 181500, 223500, \n",
    "                                140000, 250000, 143000, \n",
    "                                307000, 200000, 129900, \n",
    "                                118000]])\n",
    "\n",
    "training_x = np.array([[1710, 1262, 1786, \n",
    "                                1717, 2198, 1362, \n",
    "                                1694, 2090, 1774, \n",
    "                                1077], \n",
    "                               [2003, 1976, 2001, \n",
    "                                1915, 2000, 1993, \n",
    "                                2004, 1973, 1931, \n",
    "                                1939]])\n",
    "\n",
    "weights = least_squares_weights(training_x, training_y)\n",
    "        \n",
    "print(weights)  #--> np.array([[-2.29223802e+06],\n",
    "                        #              [ 5.92536529e+01],\n",
    "                        #              [ 1.20780450e+03]])\n",
    "                           \n",
    "print(weights[1][0]) #--> 59.25365290008861"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing en datos reales\n",
    "\n",
    "Ahora que ya hemos programado todas las funciones necesarias para calcular la regresión lineal vamos a aplicar al conjunto de datos que habíamos seleccionado al principio. \n",
    "\n",
    "**Datos:** [Kaggle's House Prices Dataset](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)\n",
    "\n",
    "Si tus funciones están correctamente programadas, la siguiente celda correrá sin problemas 😃"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = './data/train.csv'\n",
    "df = read_to_df(test_path)\n",
    "df_sub = select_columns(df, ['SalePrice', 'GrLivArea', 'YearBuilt'])\n",
    "\n",
    "cutoffs = [('SalePrice', 50000, 1e10), ('GrLivArea', 0, 4000)]\n",
    "df_sub_cutoff = column_cutoff(df_sub, cutoffs)\n",
    "\n",
    "X = df_sub_cutoff['GrLivArea'].values\n",
    "Y = df_sub_cutoff['SalePrice'].values\n",
    "\n",
    "### reshaping for input into function\n",
    "training_y = np.array([Y])\n",
    "training_x = np.array([X])\n",
    "\n",
    "weights = least_squares_weights(training_x, training_y)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_X = np.max(X) + 500\n",
    "min_X = np.min(X) - 500\n",
    "\n",
    "### Choose points evenly spaced between min_x in max_x\n",
    "reg_x = np.linspace(min_X, max_X, 1000)\n",
    "\n",
    "### Use the equation for our line to calculate y values\n",
    "reg_y = weights[0][0] + weights[1][0] * reg_x\n",
    "\n",
    "plt.plot(reg_x, reg_y, color='#58b970', label='Regression Line')\n",
    "plt.scatter(X, Y, c='k', label='Data')\n",
    "\n",
    "plt.xlabel('GrLivArea')\n",
    "plt.ylabel('SalePrice')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementación con sklearn\n",
    "\n",
    "Podemos comprobar como el resultado de nuestro código es exactamente igual al resultado de `sklearn`. Enhorabuena! Has programado tu propia **regresión lineal!!** 😃"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "### SKLearn requiere un array 2-dimensional X y 1 dimensional y.\n",
    "### skl_X = (n,1); skl_Y = (n,)\n",
    "skl_X = df_sub_cutoff[['GrLivArea']]\n",
    "skl_Y = df_sub_cutoff['SalePrice']\n",
    "\n",
    "lr.fit(skl_X,skl_Y)\n",
    "print(\"Intercept:\", lr.intercept_)\n",
    "print(\"Coefficient:\", lr.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Linear Regression - Gradient Descent\n",
    "\n",
    "En este ejercicio resolveras el mismo problema anterior pero usando **Gradient Descent**\n",
    "\n",
    "**Objetivos**:\n",
    "- Asegurar los fundamentos matemáticos detrás del Gradient Descent.\n",
    "\n",
    "**Problema**: Usando datos sobre el precio de la vivienda, intentaremos predecir el precio de una casa en base a la superficie habitable con un modelo de regresión.\n",
    "\n",
    "**Datos:** [Kaggle's House Prices Dataset](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)\n",
    "\n",
    "**Repaso:**\n",
    "\n",
    "$$ RSS(w) = \\sum_{n=1}^{N}[y_n-f(x_n)]^2 =  \\sum_{n=1}^{N}[y_n- (w_0 + \\sum_{d=1}^{D}w_dx_{nd}) ]^2 .$$\n",
    "\n",
    "Loss function:\n",
    "\n",
    "$$ RSS(w) = \\frac{1}{2}\\sum_{n=1}^{N}[y_n-f(x_n)]^2$$\n",
    "\n",
    "Y lo que queremos es minimizar esta distancia, para que el modelo se acerque lo máximo posible a los valores verdaderos.\n",
    "\n",
    "$$\\nabla RSS(w) = X^T(Xw^t-y)$$\n",
    "\n",
    "En resumen, el gradient descendiente para una regresión lineal, se basa en resolver esta ecuación de forma iterativa:\n",
    "\n",
    "$$w^{t+1} = w^t - \\eta * \\nabla RSS(w)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leer Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   GrLivArea  SalePrice\n",
      "0       1710     208500\n",
      "1       1262     181500\n",
      "2       1786     223500\n",
      "3       1717     140000\n",
      "4       2198     250000\n",
      "Shape of X:  (1460, 2)\n",
      "Shape of y: (1460,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Leer datos\n",
    "data = pd.read_csv('./data/train.csv')\n",
    "\n",
    "# Extraer dichas columnas\n",
    "newData = data[['GrLivArea','SalePrice']]\n",
    "print(newData.head())\n",
    "\n",
    "# Contruir x - y\n",
    "x = newData['GrLivArea']\n",
    "y = newData['SalePrice']\n",
    "\n",
    "# Standarizar los datos\n",
    "x = (x - x.mean()) / x.std()\n",
    "x = np.c_[np.ones(x.shape[0]), x] \n",
    "\n",
    "print(\"Shape of X: \", x.shape)\n",
    "print(\"Shape of y:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Función para encontrar los valores w usando Gradient Descent\n",
    "### Toma como argumentos: X, y, w, n_iterations, eta\n",
    "### Completa la función añadiendo la loss función y la updating rule\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "def gradient_descent_v1(x, y, w, iterations, eta):\n",
    "    \"\"\"Gradient descent\n",
    "    \n",
    "    Argumentos:\n",
    "        x -- Matriz con los datos de entrenamiento\n",
    "        y -- Vector con los datos de salida\n",
    "        w -- Vector aleatoriamente inicializado\n",
    "        iterations -- Número de iteraciones\n",
    "        eta -- Learning Rate \n",
    "    \"\"\"\n",
    "    # hay que ir iterando hasta que y1 sea menor que y0, es decir, encuentres un mínimo. \n",
    "    # Aunque en este caso consideramos un nº de iteraciones definido por input\n",
    "    # learning rate (eta) es cuánto quieres avanzar entre un punto y el siguiente de tu iteración\n",
    "    # le das una w0 (Vector aleatoriamente inicializado) para inicializar\n",
    "    # devuelve weight, loss \n",
    "\n",
    "    w0 = w\n",
    "    x_t = np.transpose(x)\n",
    "    i = 0\n",
    "    while i < iterations:\n",
    "        delta_rss = x_t @ (x @ w - y) #error inicial\n",
    "        w = w0 - eta * delta_rss\n",
    "        w0 = w\n",
    "        i += 1\n",
    "    print(w)\n",
    "    print(delta_rss)\n",
    "    return w, delta_rss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Función para encontrar los valores w usando Gradient Descent\n",
    "### Toma como argumentos: X, y, w, n_iterations, eta\n",
    "### Completa la función añadiendo la loss función y la updating rule\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "def gradient_descent(x, y, w, iterations, eta):\n",
    "    \"\"\"Gradient descent\n",
    "    \n",
    "    Argumentos:\n",
    "        x -- Matriz con los datos de entrenamiento\n",
    "        y -- Vector con los datos de salida\n",
    "        w -- Vector aleatoriamente inicializado\n",
    "        iterations -- Número de iteraciones\n",
    "        eta -- Learning Rate \n",
    "    \"\"\"\n",
    "    # hay que ir iterando hasta que y1 sea menor que y0, es decir, encuentres un mínimo. \n",
    "    # Aunque en este caso consideramos un nº de iteraciones definido por input\n",
    "    # learning rate (eta) es cuánto quieres avanzar entre un punto y el siguiente de tu iteración\n",
    "    # le das una w0 (Vector aleatoriamente inicializado) para inicializar\n",
    "    # devuelve weight, loss \n",
    "    # weigths tiene que tener tamaño [numero_iteraciones,tamaño_pesos]\n",
    "    # loss tiene que ser de tamaño [número_iteraciones]\n",
    "    \n",
    "    weight = np.zeros([iterations, w.size])\n",
    "    loss = np.zeros([iterations,w.size])\n",
    "    \n",
    "    w0 = w\n",
    "    x_t = np.transpose(x)\n",
    "    i = 0\n",
    "    \n",
    "    while i < iterations:\n",
    "        delta_rss = x_t @ (x @ w - y) #error inicial\n",
    "        w = w0 - eta * delta_rss\n",
    "        weight[i] = w\n",
    "        loss [i] = delta_rss\n",
    "        w0 = w\n",
    "        i += 1\n",
    "\n",
    "    return weight, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "w = np.random.rand(2)\n",
    "weight = np.zeros([2000, w.size])\n",
    "print(weight)\n",
    "loss = np.zeros([10,])\n",
    "print(loss)\n",
    "\n",
    "weight[0][0] =1\n",
    "print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed para inicializar w\n",
    "np.random.seed(123)\n",
    "w0 = np.random.rand(2)\n",
    "print(w0.shape)        \n",
    "training_y = np.array([208500, 181500, 223500, \n",
    "                                140000, 250000])\n",
    "training_x = np.array([[ 1.        ,  0.37020659],\n",
    "                        [ 1.        , -0.48234664],\n",
    "                        [ 1.        ,  0.51483616],\n",
    "                        [ 1.        ,  0.38352774],\n",
    "                        [ 1.        ,  1.29888065]])\n",
    "\n",
    "delta_rss = np.transpose(training_x) @ (training_x @ w0  - training_y)\n",
    "delta_rss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[183845.82320222  40415.66453324]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Learning rate\n",
    "eta = 0.01 \n",
    "\n",
    "# Número de iteraciones\n",
    "iterations = 2000 #No. of iterations\n",
    "\n",
    "# Seed para inicializar w\n",
    "np.random.seed(123)\n",
    "w0 = np.random.rand(2)\n",
    "        \n",
    "training_y = np.array([208500, 181500, 223500, \n",
    "                                140000, 250000])\n",
    "training_x = np.array([[ 1.        ,  0.37020659],\n",
    "                        [ 1.        , -0.48234664],\n",
    "                        [ 1.        ,  0.51483616],\n",
    "                        [ 1.        ,  0.38352774],\n",
    "                        [ 1.        ,  1.29888065]])\n",
    "                            \n",
    "weights, loss = gradient_descent(training_x, training_y, w0, iterations, eta)\n",
    "        \n",
    "print(weights[-1])  #--> np.array([183845.82320222  40415.66453324]) \n",
    "                    #coge el último peso, el de la última iteracion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez construida nuestra función para el Gradient Descent podemos usarla para encontrar los valores optimos de $w$. **Prueba a modificar el learning rate para ver la convergencia del Gradient Descent.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[180921.19589041  56294.90210563]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Learning rate\n",
    "eta = 0.001 \n",
    "\n",
    "# Número de iteraciones\n",
    "iterations = 1000 #No. of iterations\n",
    "\n",
    "# Seed para inicializar w\n",
    "np.random.seed(123)\n",
    "w0 = np.random.rand(2)\n",
    "\n",
    "weights, loss = gradient_descent(x, y, w0, iterations, eta)\n",
    "\n",
    "print(weights[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos creado la siguiente función para ver como Gradient Descent encuentra el resultado final - **Tarda un poco**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MovieWriter imagemagick unavailable; using Pillow instead.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\animation.py:236\u001b[0m, in \u001b[0;36mAbstractMovieWriter.saving\u001b[1;34m(self, fig, outfile, dpi, *args, **kwargs)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 236\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\animation.py:1091\u001b[0m, in \u001b[0;36mAnimation.save\u001b[1;34m(self, filename, writer, fps, dpi, codec, bitrate, extra_args, metadata, extra_anim, savefig_kwargs, progress_callback)\u001b[0m\n\u001b[0;32m   1089\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m anim, d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(all_anim, data):\n\u001b[0;32m   1090\u001b[0m     \u001b[38;5;66;03m# TODO: See if turning off blit is really necessary\u001b[39;00m\n\u001b[1;32m-> 1091\u001b[0m     \u001b[43manim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_draw_next_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m progress_callback \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\animation.py:1126\u001b[0m, in \u001b[0;36mAnimation._draw_next_frame\u001b[1;34m(self, framedata, blit)\u001b[0m\n\u001b[0;32m   1125\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pre_draw(framedata, blit)\n\u001b[1;32m-> 1126\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_draw_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframedata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post_draw(framedata, blit)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\animation.py:1720\u001b[0m, in \u001b[0;36mFuncAnimation._draw_frame\u001b[1;34m(self, framedata)\u001b[0m\n\u001b[0;32m   1718\u001b[0m \u001b[38;5;66;03m# Call the func with framedata and args. If blitting is desired,\u001b[39;00m\n\u001b[0;32m   1719\u001b[0m \u001b[38;5;66;03m# func needs to return a sequence of any artists that were modified.\u001b[39;00m\n\u001b[1;32m-> 1720\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_drawn_artists \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframedata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blit:\n",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36manimate\u001b[1;34m(i)\u001b[0m\n\u001b[0;32m     26\u001b[0m line\u001b[38;5;241m.\u001b[39mset_data(x, y)\n\u001b[1;32m---> 27\u001b[0m annotation\u001b[38;5;241m.\u001b[39mset_text(\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mloss = \u001b[39;49m\u001b[38;5;132;43;01m%.2f\u001b[39;49;00m\u001b[38;5;124;43m e10\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m10000000000\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m line, annotation\n",
      "\u001b[1;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 33>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m line, annotation\n\u001b[0;32m     30\u001b[0m anim \u001b[38;5;241m=\u001b[39m animation\u001b[38;5;241m.\u001b[39mFuncAnimation(fig, animate, init_func\u001b[38;5;241m=\u001b[39minit,\n\u001b[0;32m     31\u001b[0m                                frames\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m, interval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, blit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 33\u001b[0m \u001b[43manim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43manimation.gif\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimagemagick\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Visualizar la animación\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mio\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\animation.py:1095\u001b[0m, in \u001b[0;36mAnimation.save\u001b[1;34m(self, filename, writer, fps, dpi, codec, bitrate, extra_args, metadata, extra_anim, savefig_kwargs, progress_callback)\u001b[0m\n\u001b[0;32m   1093\u001b[0m         progress_callback(frame_number, total_frames)\n\u001b[0;32m   1094\u001b[0m         frame_number \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1095\u001b[0m writer\u001b[38;5;241m.\u001b[39mgrab_frame(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msavefig_kwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    135\u001b[0m     value \u001b[38;5;241m=\u001b[39m typ()\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\animation.py:238\u001b[0m, in \u001b[0;36mAbstractMovieWriter.saving\u001b[1;34m(self, fig, outfile, dpi, *args, **kwargs)\u001b[0m\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m--> 238\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinish\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\animation.py:514\u001b[0m, in \u001b[0;36mPillowWriter.finish\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfinish\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 514\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_frames\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39msave(\n\u001b[0;32m    515\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutfile, save_all\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, append_images\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_frames[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    516\u001b[0m         duration\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m1000\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfps), loop\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "# Definir figure\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "plt.title('Sale Price vs Living Area')\n",
    "plt.xlabel('Living Area in square feet (normalised)')\n",
    "plt.ylabel('Sale Price ($)')\n",
    "plt.scatter(x[:,1], y, color='red')\n",
    "line, = ax.plot([], [], lw=2)\n",
    "annotation = ax.text(-1, 700000, '')\n",
    "annotation.set_animated(True)\n",
    "plt.close()\n",
    "\n",
    "# Generar animacion de los datos\n",
    "def init():\n",
    "    line.set_data([], [])\n",
    "    annotation.set_text('')\n",
    "    return line, annotation\n",
    "\n",
    "# Función para la animación\n",
    "def animate(i):\n",
    "    x = np.linspace(-5, 20, 1000)\n",
    "    y = weights[i][1]*x + weights[i][0]\n",
    "    line.set_data(x, y)\n",
    "    annotation.set_text('loss = %.2f e10' % (loss[i]/10000000000))\n",
    "    return line, annotation\n",
    "\n",
    "anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                               frames=300, interval=0, blit=True)\n",
    "\n",
    "anim.save('animation.gif', writer='imagemagick', fps = 30)\n",
    "\n",
    "# Visualizar la animación\n",
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "\n",
    "filename = 'animation.gif'\n",
    "\n",
    "video = io.open(filename, 'r+b').read()\n",
    "encoded = base64.b64encode(video)\n",
    "HTML(data='''<img src=\"data:image/gif;base64,{0}\" type=\"gif\" />'''.format(encoded.decode('ascii')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Opcional) - Calculando similitud entre páginas web\n",
    "\n",
    "Este ejercicio pondrá a prueba tu capacidad para encontrar la similitud entre vectores usando cosine similarity.\n",
    "\n",
    "**Objetivos**:\n",
    "- Usar `Python` + `BeautifulSoup` para \"scrapear\" páginas webs.\n",
    "- Asegurar los fundamentos matemáticos detrás del cosine similarity.\n",
    "\n",
    "**Problema**: Dadas N páginas web, extraer el texto de ellas y determinar la similitud.\n",
    "\n",
    "### Repaso\n",
    "\n",
    "Como recordarás, podemos medir la similitud entre vectores usando la siguiente ecuación:<br>\n",
    "\n",
    "<center>$\\overrightarrow{u} \\cdot \\overrightarrow{v} = |\\overrightarrow{u}||\\overrightarrow{v}| \\cos \\theta $</center>\n",
    "\n",
    "Que podemos reescribir de la siguiente forma:<br>\n",
    "\n",
    "<center>$\\cos \\theta = \\frac{\\overrightarrow{u} \\cdot \\overrightarrow{v}}{|\\overrightarrow{u}||\\overrightarrow{v}|}$</center>\n",
    "\n",
    "La **similitud** va a venir dada por el ángulo $\\theta$, que nos indicará lo siguiente:\n",
    "\n",
    "<img src=\"./Images/cosine_sim.png\" width=70%/>\n",
    "\n",
    "### Web scraping\n",
    "\n",
    "La técnica llamada `web scraping` es la utilizada normalmente para extraer contenido de páginas webs y posteriormente procesarlos. Por ejemplo, si quisieramos construir una base de datos para entrenar un modelo con imágenes de ropa para hombres, podríamos intentar \"scrapear\" dicha sección de la página web del El Corte Inglés para conseguir las imágenes (no es tan fácil como suena)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estas librerias deben ser instaladas para hacer este ejercicio\n",
    "!pip install beautifulsoup4\n",
    "!pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import lxml\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import urllib.request\n",
    "\n",
    "url = \"https://es.wikipedia.org/wiki/Canis_lupus_familiaris\"\n",
    "\n",
    "def parse_from_url(url):\n",
    "    \"\"\"\n",
    "    Función para extraer el contenido (raw text) de una página web\n",
    "    \"\"\"\n",
    "    \n",
    "    html = urllib.request.urlopen(url).read()\n",
    "    soup = BeautifulSoup(html, \"html.parser\" )\n",
    "    for script in soup([\"script\", \"style\"]):\n",
    "        script.extract()\n",
    "        \n",
    "    text = soup.get_text()\n",
    "    \n",
    "    # Eliminar saltos de linea\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    return text\n",
    "\n",
    "parse_from_url(url)[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Escribe una función que reciba una lista de urls\n",
    "### Aplica web scraping a cada una de ellas para extraer el contenido\n",
    "### Y devuelva un diccionario con el contenido por cada url\n",
    "\n",
    "### HINT: Usa la función anterior\n",
    "### NOTE: Suele tardar un poco en extraer el contenido de las paginas web\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "def get_content(url_ls):\n",
    "    \"\"\"Extrae el contenido de una lista de urls\n",
    "    \n",
    "    Argumentos:\n",
    "        url_ls -- Lista con urls\n",
    "        \n",
    "    Ejemplo:\n",
    "        url_ls = ['https://es.wikipedia.org/wiki/Canis_lupus_familiaris', \n",
    "        'https://es.wikipedia.org/wiki/Canis_lupus',\n",
    "        'https://es.wikipedia.org/wiki/Felis_silvestris_catus']\n",
    "        \n",
    "        url2content = get_content(url_ls)  \n",
    "    \n",
    "    Requerimientos:\n",
    "        Esta función depende de 'parse_from_url()'\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesado\n",
    "\n",
    "Como es lógico, no podemos resolver esta ecuación $\\cos \\theta = \\frac{\\overrightarrow{u} \\cdot \\overrightarrow{v}}{|\\overrightarrow{u}||\\overrightarrow{v}|}$ usando texto sin más, debemos convertir cada página web a un vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Escribe una función que reciba texto\n",
    "### Y devuelva una lista con el texto separado por espacios\n",
    "### Además del set de la lista\n",
    "### \"hola que que tal\" - [\"hola\", \"que\", \"que\", \"tal\"], {\"hola\", \"que\", \"tal\"}\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "def tokenizer(text):\n",
    "    \"\"\"Divide el texto en palabras\n",
    "    \n",
    "    Argumentos:\n",
    "        text -- String\n",
    "        \n",
    "    Ejemplo:\n",
    "        url_ls = \"Hola me llamo llamo Alex y estamos aprendiendo Algebra y estamos bien\"\n",
    "        \n",
    "        tokens_txt, set_txt = tokenizer(url_ls)  \n",
    "    \n",
    "    Requerimientos:\n",
    "        No uses ningún tokenizer ya implementado (nltk, spacy, ...)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente paso es crear un conjunto con las palabras de ambas páginas web (unión), por ejemplo:\n",
    "\n",
    "- Los perros son maravillosos...\n",
    "- Los maravillosos años 80...\n",
    "\n",
    "Por tanto, el conjunto para estas dos frases sería `{\"los\", \"perros\", \"son\", \"maravillosos\", \"años\", \"80\"}`. Debemos realizar esto para todas las combinaciones posibles, es decir:\n",
    "\n",
    "- web_1\n",
    "- web_2\n",
    "- web_3\n",
    "\n",
    "En este caso, las combinaciones serían (no importa el orden) `[web_1, web_2]`, `[web_1, web_3]`, `[web_2, web_3]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Escribe una función que recibe una lista de N páginas web\n",
    "### Y calcula todas las combinaciones posibles entre ellas, no importa el orden\n",
    "### [web_1, web_2, web_3, ...]\n",
    "### Devuelve una lista de tuples con las combinaciones [(web_1, web_2), (web_1, web_3), ...]\n",
    "\n",
    "# HINT: Puedes implementar esta función como quieras pero la librería itertools \n",
    "#       proporciona una función llamada `combinations` para realizar esta tarea.\n",
    "\n",
    "### TU RESPUESTA ABAJO\n",
    "import itertools\n",
    "    \n",
    "def combinations(url_ls):\n",
    "    \"\"\"Calcula todas las combinaciones posibles entre los elementos de una lista\n",
    "    \n",
    "    Argumentos:\n",
    "        url_ls -- Lista de urls\n",
    "        \n",
    "    Ejemplo:\n",
    "        url_ls = ['https://es.wikipedia.org/wiki/Canis_lupus_familiaris', \n",
    "        'https://es.wikipedia.org/wiki/Canis_lupus',\n",
    "        'https://es.wikipedia.org/wiki/Felis_silvestris_catus']\n",
    "        \n",
    "        permutation = combinations(url_ls)  \n",
    "    \n",
    "    Requerimientos:\n",
    "        Puedes implementar esta función como quieras pero la librería itertools \n",
    "        proporciona una función llamada `combinations` para realizar esta tarea.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Escribe una función que recibe una lista con tuples\n",
    "### [({'que', 'hola'}, {'que', 'es', 'guay'}), ({'que', 'hola'}, {'madrid', 'la', 'es'})]\n",
    "### Y devuelve una lista con la union de los conjuntos\n",
    "### [({'que', 'hola', 'es', 'guay'}), ({'que', 'hola', 'madrid', 'la', 'es'})]\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "def union(comb_ls):\n",
    "    \"\"\"Calcula la unión por cada tuple de una lista \n",
    "    \n",
    "    Argumentos:\n",
    "        comb_ls -- Lista de tuples\n",
    "        \n",
    "    Ejemplo:\n",
    "        comb_ls = [({'que', 'hola'}, {'que', 'es', 'guay'}), ({'que', 'hola'}, {'madrid', 'la', 'es'})]\n",
    "        \n",
    "        union_ls = union(comb_ls)  # -> [{'es', 'que', 'hola', 'guay'}, {'es', 'que', 'hola', 'madrid', 'la'}]\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que tenemos una lista de conjuntos por cada par de páginas web, podemos convertir el texto de la página web a un vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set2vector(tokens_web1, tokens_web_2, set_web1, set_web2):\n",
    "    \"\"\"\n",
    "    Función para convertir un conjunto a vector\n",
    "    \n",
    "    Argumentos:\n",
    "        tokens_web1 -- Contenido tokenizado de página web 1\n",
    "        tokens_web_2 -- Contenido tokenizado de página web 2\n",
    "        set_web1 -- Conjunto de palabras de la página web 1\n",
    "        set_web2 -- Conjunto de palabras de la página web 2\n",
    "        \n",
    "    Ejemplo:\n",
    "        tokens_web1 = [\"hola\", \"que\", \"tal\", \"soy\", \"Alex\"]\n",
    "        tokens_web_2 = [\"hola\", \"me\", \"llamo\"]\n",
    "        set_web1 = {\"hola\", \"que\", \"tal\"}\n",
    "        set_web2 = {\"hola\", \"me\", \"llamo\"}\n",
    "        union_ls = set2vector(tokens_web1, tokens_web_2, set_web1, set_web2)  \n",
    "        \n",
    "    Requerimientos:\n",
    "        Depende de la función `union()`\n",
    "    \"\"\"\n",
    "    \n",
    "    # Unimos los conjuntos\n",
    "    join_set = union([(set_web1, set_web2)])[0]\n",
    "    \n",
    "    web1_array = []\n",
    "    web2_array = [] \n",
    "\n",
    "    for word in join_set:\n",
    "        if word in tokens_web1:\n",
    "            web1_array.append(1)\n",
    "        else:\n",
    "            web1_array.append(0)\n",
    "        if word in tokens_web_2:\n",
    "            web2_array.append(1)\n",
    "        else:\n",
    "            web2_array.append(0)\n",
    "\n",
    "    return web1_array, web2_array\n",
    "\n",
    "tokens_web1 = [\"hola\", \"que\", \"tal\", \"soy\", \"Alex\"]\n",
    "tokens_web_2 = [\"hola\", \"me\", \"llamo\"]\n",
    "set_web1 = {\"hola\", \"que\", \"tal\", \"soy\", \"Alex\"}\n",
    "set_web2 = {\"hola\", \"me\", \"llamo\"}\n",
    "web1_array, web2_array = set2vector(tokens_web1, tokens_web_2, set_web1, set_web2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(web1_array, web2_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity\n",
    "\n",
    "Por último, ya podemos implementar la ecuación: $\\cos \\theta = \\frac{\\overrightarrow{u} \\cdot \\overrightarrow{v}}{|\\overrightarrow{u}||\\overrightarrow{v}|}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Escribe una función que recibe dos vectores, u y v\n",
    "### Y devuelva la similaridad entre ambos vectores\n",
    "###\n",
    "### Paso 1: Si u y v son listas -> Convertirlo a arrays\n",
    "###\n",
    "### Paso 2: Calcula la similaridad entre ambos vectores\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(u, v):\n",
    "    \"\"\"Calcula la similaridad entre dos vectores\n",
    "    \n",
    "    Argumentos:\n",
    "        u -- Vector 1\n",
    "        v -- Vector 2\n",
    "        \n",
    "    Ejemplo:\n",
    "        u = np.array([1, 2, 3])\n",
    "        v = np.array([3, 2, 1])\n",
    "        \n",
    "        similarity = cosine_similarity(u, v)  # -> 0.71428\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def websites_sim(url_ls):\n",
    "    \"\"\"Función para calcular la similaridad entre páginas web\n",
    "    \n",
    "    Argumentos:\n",
    "        url_ls -- Listas de páginas web\n",
    "        \n",
    "    Ejemplo:\n",
    "        url_ls = ['https://es.wikipedia.org/wiki/Canis_lupus_familiaris', \n",
    "        'https://es.wikipedia.org/wiki/Canis_lupus',\n",
    "        'https://es.wikipedia.org/wiki/Felis_silvestris_catus']\n",
    "        \n",
    "        similarity_ls = websites_sim(url_ls)  \n",
    "    \"\"\"\n",
    "    \n",
    "    url2content = get_content(url_ls)\n",
    "    \n",
    "    # Creamos un diccionario donde cada url tendrá su contenido tokenizado y su conjunto\n",
    "    url_dict = {}\n",
    "    for url, content in url2content.items():\n",
    "        toks, sets = tokenizer(content)\n",
    "        url_dict[url] = {'tokens': toks,\n",
    "                        'unique_tokens': sets}\n",
    "    \n",
    "    # Calculamos todas las combinaciones posibles de las direcciones de las páginas web\n",
    "    comb_ls = combinations(url_ls)\n",
    "\n",
    "    # Usando comb_ls y la función `set2vector()` convertimos cada página web a vectores\n",
    "    print(\"Similaridad: \")\n",
    "    for el in comb_ls:\n",
    "        # Obtenemos los tokens y el conjunto para cada página web\n",
    "        token_1 = url_dict[el[0]]['tokens']\n",
    "        token_2 = url_dict[el[1]]['tokens']\n",
    "        set_1 = url_dict[el[0]]['unique_tokens']\n",
    "        set_2 = url_dict[el[1]]['unique_tokens']\n",
    "        array_web1, array_web2 = set2vector(token_1, token_2, set_1, set_2)\n",
    "        similarity = cosine_similarity(array_web1, array_web2)\n",
    "        \n",
    "        print(\"{} vs {} - {}\".format(el[0], el[1], round(similarity, 3)))\n",
    "\n",
    "                      \n",
    "url_ls = ['https://es.wikipedia.org/wiki/Canis_lupus_familiaris', \n",
    "'https://es.wikipedia.org/wiki/Canis_lupus',\n",
    "'https://es.wikipedia.org/wiki/Felis_silvestris_catus']\n",
    "\n",
    "similarity_ls = websites_sim(url_ls) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
